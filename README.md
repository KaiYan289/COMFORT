# üõãÔ∏è Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference Under Ambiguities

[![Paper](https://img.shields.io/badge/arXiv-Paper-b31b1b?logo=arxiv&logoColor=b31b1b)](https://arxiv.org/abs/)
[![Project Page](https://img.shields.io/badge/Project-Website-5B7493?logo=googlechrome&logoColor=5B7493)](https://spatial-comfort.github.io/)
[![Hugging Dataset](https://img.shields.io/badge/huggingface-dataset:COMFORT-green)](https://huggingface.co/datasets/sled-umich/COMFORT)

![COMFORT](comfort.jpg "COMFORT")

This repository provides the code and instructions for using the evaluation protocol to systematically assess the spatial reasoning capabilities of VLMs, <ins>CO</ins>nsistent <ins>M</ins>ultilingual <ins>F</ins>rame <ins>O</ins>f <ins>R</ins>eference <ins>T</ins>est (COMFORT). Follow the steps below to set up the environment, generate data (optional), and run experiments. Feel free to create an issue if you encounter any problems. We also welcome pull requests.

## Coming Soon